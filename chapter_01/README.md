## Chapter 1: Introduction to Data Science and Machine learning

#### What is data science?
Data science is the study of data to extract meaningful insights for business. It is a multidisciplinary approach that combines principles and practices from the fields of mathematics, statistics, artificial intelligence, and computer engineering to analyze large amounts of data. This analysis helps data scientists to ask and answer questions like what happened, why it happened, what will happen, and what can be done with the results.

##### What is Data?
Data is that data is different types of information usually formatted in a particular manner. All software is divided into two major categories:  	
We use data science to make it easier to work with data. Data science is defined as a field that combines knowledge of mathematics, programming skills, domain expertise, scientific methods, algorithms, processes, and systems to extract actionable knowledge and insights from both structured and unstructured data, then apply the knowledge gleaned from that data to a wide range of uses and domains.
Another definition Data is the foundation of data science; it is the material on which all the analyses are based. In the context of data science, there are **two** types of data: traditional, and big data.

- Traditional data: is data that is structured and stored in databases which analysts can manage from one computer; it is in table format, containing numeric or text values. Actually, the term “traditional” is something we are introducing for clarity. It helps emphasize the distinction between big data and other types of data.
- Big data: is… bigger than traditional data, and not in the trivial sense. From variety (numbers, text, but also images, audio, mobile data, etc.), to velocity (retrieved and computed in real time), to volume (measured in tera-, peta-, exa-bytes), big data is usually distributed across a network of computers.

##### Importance of Data science 
Data science is important because it combines tools, methods, and technology to generate meaning from data. Modern organizations are inundated with data; there is a proliferation of devices that can automatically collect and store information. Online systems and payment portals capture more data in the fields of e-commerce, medicine, finance, and every other aspect of human life. We have text, audio, video, and image data available in vast quantities.  

##### History of data science
While the term data science is not new, the meanings and connotations have changed over time. The word first appeared in the ’60s as an alternative name for statistics. In the late ’90s, computer science professionals formalized the term. A proposed definition for data science saw it as a separate field with three aspects: data design, collection, and analysis. It still took another decade for the term to be used outside of academia. 
Future of data science
Artificial intelligence and machine learning innovations have made data processing faster and more efficient. Industry demand has created an ecosystem of courses, degrees, and job positions within the field of data science. Because of the cross-functional skillset and expertise required, data science shows strong projected growth over the coming decades.

###### What is data science used for?
Data science is used to study data in four main ways:
1. **Descriptive analysis**
Descriptive analysis examines data to gain insights into what happened or what is happening in the data environment. It is characterized by data visualizations such as pie charts, bar charts, line graphs, tables, or generated narratives. For example, a flight booking service may record data like the number of tickets booked each day. Descriptive analysis will reveal booking spikes, booking slumps, and high-performing months for this service.
2. **Diagnostic analysis**
Diagnostic analysis is a deep-dive or detailed data examination to understand why something happened. It is characterized by techniques such as drill-down, data discovery, data mining, and correlations. Multiple data operations and transformations may be performed on a given data set to discover unique patterns in each of these techniques. For example, the flight service might drill down on a particularly high-performing month to better understand the booking spike. This may lead to the discovery that many customers visit a particular city to attend a monthly sporting event.
3. **Predictive analysis**
Predictive analysis uses historical data to make accurate forecasts about data patterns that may occur in the future. It is characterized by techniques such as machine learning, forecasting, pattern matching, and predictive modeling. In each of these techniques, computers are trained to reverse engineer causality connections in the data. For example, the flight service team might use data science to predict flight booking patterns for the coming year at the start of each year. The computer program or algorithm may look at past data and predict booking spikes for certain destinations in May. Having anticipated their customer’s future travel requirements, the company could start targeted advertising for those cities from February.
4. **Prescriptive analysis**
Prescriptive analytics takes predictive data to the next level. It not only predicts what is likely to happen but also suggests an optimum response to that outcome. It can analyze the potential implications of different choices and recommend the best course of action. It uses graph analysis, simulation, complex event processing, neural networks, and recommendation engines from machine learning.         

#### What is Information?
Information is defined as classified or organized data that has some meaningful value for the user. Information is also the processed data used to make decisions and take action. Processed data must meet the following criteria for it to be of any significant use in decision-making:
- **Accuracy**: The information must be accurate.
- **Completeness**: The information must be complete.
- **Timeliness**: The information must be available when it’s needed.

Today data is everywhere in every field. Whether you are a data scientist, marketer, businessman, data analyst, researcher, or you are in any other profession, you need to play or experiment with raw or structured data. This data is so important for us that it becomes important to handle and store it properly, without any error. While working on these data, it is important to know the types of data to process them and get the right results. There are **two types of data**: *Qualitative* and *Quantitative* data, which are further classified into:

The data is classified into four categories:
- Ordinal data.
- Discrete data.
- Continuous data.

![image-2.png](attachment:image-2.png)


##### Types of Data
######  Qualitative or Categorical Data
Qualitative or Categorical Data is data that can’t be measured or counted in the form of numbers. These types of data are sorted by category, not by number. That’s why it is also known as Categorical Data. These data consist of audio, images, symbols, or text. The gender of a person, i.e., male, female, or others, is qualitative data.

Qualitative data tells about the perception of people. This data helps market researchers understand the customers’ tastes and then design their ideas and strategies accordingly. 

The other examples of qualitative data are :
- What language do you speak
- Favorite holiday destination
- Opinion on something (agree, disagree, or neutral)
- Colors

The Qualitative data are further classified into two parts :
##### Nominal Data
Nominal Data is used to label variables without any order or quantitative value. The color of hair can be considered nominal data, as one color can’t be compared with another color.

The name “nominal” comes from the Latin name “nomen,” which means “name.” With the help of nominal data, we can’t do any numerical tasks or can’t give any order to sort the data. These data don’t have any meaningful order; their values are distributed into distinct categories.

##### Examples of Nominal Data :

- Colour of hair (Blonde, red, Brown, Black, etc.)
- Marital status (Single, Widowed, Married)
- Nationality (Indian, German, American)
- Gender (Male, Female, Others)
- Eye Color (Black, Brown, etc.)

##### Ordinal Data
Ordinal data have natural ordering where a number is present in some kind of order by their position on the scale. These data are used for observation like customer satisfaction, happiness, etc., but we can’t do any arithmetical tasks on them. 

Ordinal data is qualitative data for which their values have some kind of relative position. These kinds of data can be considered “in-between” qualitative and quantitative data. The ordinal data only shows the sequences and cannot use for statistical analysis. Compared to nominal data, ordinal data have some kind of order that is not present in nominal data.  

###### Examples of Ordinal Data :
- When companies ask for feedback, experience, or satisfaction on a scale of 1 to 10
- Letter grades in the exam (A, B, C, D, etc.)
- Ranking of people in a competition (First, Second, Third, etc.)
- Economic Status (High, Medium, and Low)
- Education Level (Higher, Secondary, Primary)

##### Quantitative Data
Quantitative data can be expressed in numerical values, making it countable and including statistical data analysis. These kinds of data are also known as Numerical data. 
It answers the questions like “how much,” “how many,” and “how often.” For example, the price of a phone, the computer’s ram, the height or weight of a person, etc., falls under quantitative data. 
Quantitative data can be used for statistical manipulation. These data can be represented on a wide variety of graphs and charts, such as bar graphs, histograms, scatter plots, boxplots, pie charts, line graphs, etc.

###### Examples of Quantitative Data : 
- Height or weight of a person or object
- Room Temperature
- Scores and Marks (Ex: 59, 80, 60, etc.) Time

##### Discrete Data
The term discrete means distinct or separate. The discrete data contain the values that fall under integers or whole numbers. The total number of students in a class is an example of discrete data. These data can’t be broken into decimal or fraction values.
The discrete data are countable and have finite values; their subdivision is not possible. These data are represented mainly by a bar graph, number line, or frequency table.

##### Examples of Discrete Data : 
- Total numbers of students present in a class
- Cost of a cell phone
- Numbers of employees in a company
- The total number of players who participated in a competition
- Days in a week

#### Continuous Data
Continuous data are in the form of fractional numbers. It can be the version of an android phone, the height of a person, the length of an object, etc. Continuous data represents information that can be divided into smaller levels. The continuous variable can take any value within a range. 

The key difference between discrete and continuous data is that discrete data contains the integer or whole number. Still, continuous data stores the fractional numbers to record different types of data such as temperature, height, width, time, speed, etc.

##### Examples of Continuous Data : 
- Height of a person
- Speed of a vehicle
- “Time-taken” to finish the work 
- Wi-Fi Frequency
- Market share price

### What is Machine Learning?

Machine Learning, often abbreviated as ML, is a subset of **artificial intelligence** (AI) that focuses on the development of computer algorithms that improve automatically through experience and by the use of data. In simpler terms, machine learning enables computers to learn from data and make decisions or predictions without being explicitly programmed to do so.

At its core, machine learning is all about creating and implementing algorithms that facilitate these decisions and predictions. These algorithms are designed to improve their performance over time, becoming more accurate and effective as they process more data.

In traditional programming, a computer follows a set of predefined instructions to perform a task. However, in machine learning, the computer is given a set of data and a task to perform, but it's up to the computer to figure out how to accomplish the task based on the examples it's given.

For instance, if we want a computer to recognize images of cats, we don't provide it with specific instructions on what a cat looks like. Instead, we give it thousands of images of cats and let the machine learning algorithm figure out the common patterns and features that define a cat. Over time, as the algorithm processes more images, it gets better at recognizing cats, even when presented with images it has never seen before.

This ability to learn from data and improve over time makes machine learning incredibly powerful and versatile. It's the driving force behind many of the technological advancements we see today, from voice assistants and recommendation systems to self-driving cars and predictive analytics.

#### Machine learning vs AI vs deep learning

Machine learning is often confused with artificial intelligence or deep learning. Let's take a look at how these terms differ from one another. For a more in-depth look, check out our comparison guides on **AI vs machine learning** and **machine learning vs deep learning**. 

**AI** refers to the development of programs that behave intelligently and mimic human intelligence through a set of algorithms. The field focuses on three skills: learning, reasoning, and self-correction to obtain maximum efficiency. AI can refer to either machine learning-based programs or even explicitly programmed computer programs.

**Machine learning** is a subset of AI, which uses algorithms that learn from data to make predictions. These predictions can be generated through supervised learning, where algorithms learn patterns from existing data, or unsupervised learning, where they discover general patterns in data. ML models can predict numerical values based on historical data, categorize events as true or false, and cluster data points based on commonalities.

**Deep learning**, on the other hand, is a subfield of machine learning dealing with algorithms based essentially on multi-layered **artificial neural networks** (ANN) that are inspired by the structure of the human brain.

Unlike conventional machine learning algorithms, deep learning algorithms are less linear, more complex, and hierarchical, capable of learning from enormous amounts of data, and able to produce highly accurate results. Language translation, image recognition, and personalized medicines are some examples of **deep learning applications**.

![image-3.png](attachment:image-3.png)

#### The Importance of Machine Learning

In the 21st century, data is the new oil, and machine learning is the engine that powers this data-driven world. It is a critical technology in today's digital age, and its importance cannot be overstated. This is reflected in the industry's projected growth, with the US Bureau of Labor Statistics predicting a **21% growth in jobs between 2021 and 2031**.

Here are some reasons why it’s so essential in the modern world:

- **Data processing.** One of the primary reasons machine learning is so important is its ability to handle and make sense of large volumes of data. With the explosion of digital data from social media, sensors, and other sources, traditional data analysis methods have become inadequate. Machine learning algorithms can process these vast amounts of data, uncover hidden patterns, and provide valuable insights that can drive decision-making.
- **Driving innovation.** Machine learning is driving innovation and efficiency across various sectors. Here are a few examples:
  - **Healthcare**. Algorithms are used to predict disease outbreaks, personalize patient treatment plans, and improve medical imaging accuracy.
  - **Finance**. Machine learning is used for credit scoring, algorithmic trading, and fraud detection.
  - **Retail**. Recommendation systems, supply chains, and **customer service** can all benefit from machine learning.
  - The techniques used also find applications in sectors as diverse as agriculture, education, and entertainment.
- **Enabling automation**. Machine learning is a key enabler of automation. By learning from data and improving over time, machine learning algorithms can perform previously manual tasks, freeing humans to focus on more complex and creative tasks. This not only increases efficiency but also opens up new possibilities for innovation.

 #### How Does Machine Learning Work?

  Understanding how machine learning works involves delving into a step-by-step process that transforms raw data into valuable insights. Let's break down this process:

  ![image-4.png](attachment:image-4.png)

  **Step 1: Data collection**

  The first step in the machine learning process is data collection. Data is the lifeblood of machine learning - the quality and quantity of your data can directly impact your model's performance. Data can be collected from various sources such as databases, text files, images, audio files, or even scraped from the web.

  Once collected, the data needs to be prepared for machine learning. This process involves organizing the data in a suitable format, such as a CSV file or a database, and ensuring that the data is relevant to the problem you're trying to solve.

  **Step 2: Data preprocessing**

  Data preprocessing is a crucial step in the machine learning process. It involves cleaning the data (removing duplicates, correcting errors), handling missing data (either by removing it or filling it in), and normalizing the data (scaling the data to a standard format).

  Preprocessing improves the quality of your data and ensures that your machine learning model can interpret it correctly. This step can significantly improve the accuracy of your model. Our course, **Preprocessing for Machine Learning in Python**, explores how to get your cleaned data ready for modeling.

  **Step 3: Choosing the right model**

  Once the data is prepared, the next step is to choose a machine learning model. There are many types of models to choose from, including linear regression, decision trees, and neural networks. The choice of model depends on the nature of your data and the problem you're trying to solve.

  Factors to consider when choosing a model include the size and type of your data, the complexity of the problem, and the computational resources available. You can read more about **the different machine learning models** in a separate article.

  **Step 4: Training the model**

  After choosing a model, the next step is to train it using the prepared data. Training involves feeding the data into the model and allowing it to adjust its internal parameters to better predict the output.

  During training, it's important to avoid overfitting (where the model performs well on the training data but poorly on new data) and underfitting (where the model performs poorly on both the training data and new data). You can learn more about the full machine learning process in our **Machine Learning Fundamentals with Python** skill track, which explores the essential concepts and how to apply them.

  **Step 5: Evaluating the model**

  Once the model is trained, it's important to evaluate its performance before deploying it. This involves testing the model on new data it hasn't seen during training.

  Common metrics for evaluating a model's performance include accuracy (for classification problems), precision and recall (for binary classification problems), and mean squared error (for regression problems). We cover this evaluation process in more detail in our **Responsible AI webinar**.

  **Step 6: Hyperparameter tuning and optimization**

  After evaluating the model, you may need to adjust its hyperparameters to improve its performance. This process is known as parameter tuning or hyperparameter optimization.

  Techniques for hyperparameter tuning include grid search (where you try out different combinations of parameters) and cross validation (where you divide your data into subsets and train your model on each subset to ensure it performs well on different data).

  We have a separate article on **hyperparameter optimization in machine learning models**, which covers the topic in more detail.

  **Step 7: Predictions and deployment**

  Once the model is trained and optimized, it's ready to make predictions on new data. This process involves feeding new data into the model and using the model's output for decision-making or further analysis.

  Deploying the model involves integrating it into a production environment where it can process real-world data and provide real-time insights. This process is often known as MLOps. Discover more about **MLOps** in a separate tutorial.

  ###### Types of Machine Learning

  Machine learning can be broadly classified into three types based on the nature of the learning system and the data available: supervised learning, unsupervised learning, and reinforcement learning. Let's delve into each of these:

  **Supervised learning**

  **Supervised learning** is the most common type of machine learning. In this approach, the model is trained on a labeled dataset. In other words, the data is accompanied by a label that the model is trying to predict. This could be anything from a category label to a real-valued number.

  The model learns a mapping between the input (features) and the output (label) during the training process. Once trained, the model can predict the output for new, unseen data.

  Common examples of supervised learning algorithms include **linear regression** for regression problems and logistic regression, **decision trees**, and support vector machines for classification problems. In practical terms, this could look like an image recognition process, wherein a dataset of images where each picture is labeled as "cat," "dog," etc., a supervised model can recognize and categorize new images accurately.

  **Unsupervised learning**

  **Unsupervised learning**, on the other hand, involves training the model on an unlabeled dataset. The model is left to find patterns and relationships in the data on its own.

  This type of learning is often used for clustering and dimensionality reduction. Clustering involves grouping similar data points together, while dimensionality reduction involves reducing the number of random variables under consideration by obtaining a set of principal variables.

  Common examples of unsupervised learning algorithms include **k-means for clustering problems** and **Principal Component Analysis** (PCA) for dimensionality reduction problems. Again, in practical terms, in the field of marketing, unsupervised learning is often used to segment a company's customer base. By examining purchasing patterns, demographic data, and other information, the algorithm can group customers into segments that exhibit similar behaviors without any pre-existing labels.

 ![image-5.png](attachment:image-5.png)

  *Comparing supervised and unsupervised learning*

  **Reinforcement learning**

  **Reinforcement learning** is a type of machine learning where an agent learns to make decisions by interacting with its environment. The agent is rewarded or penalized (with points) for the actions it takes, and its goal is to maximize the total reward.

  Unlike supervised and unsupervised learning, reinforcement learning is particularly suited to problems where the data is sequential, and the decision made at each step can affect future outcomes.

  Common examples of reinforcement learning include game playing, robotics, resource management, and many more.

  ###### Understanding the Impact of Machine Learning

  Machine Learning has had a transformative impact across various industries, revolutionizing traditional processes and paving the way for innovation. Let's explore some of these impacts:

  **Healthcare**

  In healthcare, machine learning is used to predict disease outbreaks, personalize patient treatment plans, and improve medical imaging accuracy. For instance, **Google's DeepMind Health** is working with doctors to build machine learning models to detect diseases earlier and improve patient care.

  **Finance**

  The finance sector has also greatly benefited from machine learning. It's used for credit scoring, algorithmic trading, and fraud detection. A recent survey found that **56% of global executives** said that artificial intelligence (AI) and machine learning have been implemented into financial crime compliance programs.

  **Transportation**

  Machine learning is at the heart of the self-driving car revolution. Companies like Tesla and Waymo use machine learning algorithms to interpret sensor data in real-time, allowing their vehicles to recognize objects, make decisions, and navigate roads autonomously. Similarly, the Swedish Transport Administration recently started **working with computer vision and machine learning specialists** to optimize the country’s road infrastructure management.

  **Some Applications of Machine Learning**

  Machine learning applications are all around us, often working behind the scenes to enhance our daily lives. Here are some real-world examples:

  **Recommendation systems**

  Recommendation systems are one of the most visible applications of machine learning. Companies like Netflix and Amazon use machine learning to analyze your past behavior and recommend products or movies you might like. Learn how to **build a recommendation engine in Python** with our online course.

  **Voice assistants**

  Voice assistants like Siri, Alexa, and Google Assistant use machine learning to understand your voice commands and provide relevant responses. They continually learn from your interactions to improve their performance.

  **Fraud detection**

  Banks and credit card companies use machine learning to detect fraudulent transactions. By analyzing patterns of normal and abnormal behavior, they can flag suspicious activity in real-time. We have a **fraud detection in Python course**, which explores the concept in more detail.

  **Social media**

  Social media platforms use machine learning for a variety of tasks, from personalizing your feed to filtering out inappropriate content.

 ![image-6.png](attachment:image-6.png)

  *Our **machine learning cheat sheet** covers different algorithms and their uses*

  ### Machine Learning Tools

  In the world of machine learning, having the right tools is just as important as understanding the concepts. These tools, which include programming languages and libraries, provide the building blocks to implement and deploy machine learning algorithms. Let's explore some of the most popular tools in machine learning:

  **Python for machine learning**

  Python is a popular language for machine learning due to its simplicity and readability, making it a great choice for beginners. It also has a strong ecosystem of libraries that are tailored for machine learning.

  Libraries such as NumPy and Pandas are used for data manipulation and analysis, while Matplotlib is used for data visualization. Scikit-learn provides a wide range of machine learning algorithms, and TensorFlow and PyTorch are used for building and training neural networks.

  **R for machine learning**

  R is another language widely used in machine learning, particularly for statistical analysis. It has a rich ecosystem of packages that make it easy to implement machine learning algorithms.

  Packages like caret, mlr, and randomForest provide a variety of machine learning algorithms, from regression and classification to clustering and dimensionality reduction.

  **TensorFlow**

  TensorFlow is a powerful open-source library for numerical computation, particularly well-suited for large-scale machine learning. It was developed by the Google Brain team and supports both CPUs and GPUs.

  TensorFlow allows you to build and train complex neural networks, making it a popular choice for deep learning applications.

  **Scikit-learn**

  Scikit-learn is a Python library that provides a wide range of machine learning algorithms for both supervised and unsupervised learning. It's known for its clear API and detailed documentation.

  Scikit-learn is often used for data mining and data analysis, and it integrates well with other Python libraries like NumPy and Pandas.

  **Keras**

  Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.

  Keras provides a user-friendly interface for building and training neural networks, making it a great choice for beginners in deep learning.

  ###### The Top Machine Learning Careers in 2023

  Machine learning has opened up a wide range of career opportunities. From data science to AI engineering, professionals with machine learning skills are in high demand. Let's explore some of these career paths:

  **Data scientist**

  A **data scientist** uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Machine learning is a key tool in a data scientist's arsenal, allowing them to make predictions and uncover patterns in data.

  Key skills:

- Statistical analysis
- Programming (Python, R)
- Machine learning
- Data visualization
- Problem-solving

  Essential tools:

- Python
- R
- SQL
- Hadoop
- Spark
- Tableau

  **Machine learning engineer**

  A **machine learning engineer** designs and implements machine learning systems. They run machine learning experiments using programming languages like Python and R, work with datasets, and apply machine learning algorithms and libraries.

  Key skills:

- Programming (Python, Java, R)
- Machine learning algorithms
- Statistics
- System design

  Essential tools:

- Python
- TensorFlow
- Scikit-learn
- PyTorch
- Keras

  **Research scientist**

  A research scientist in machine learning conducts research to advance the field of machine learning. They work in both academic and industry settings, developing new algorithms and techniques.

  Key skills:

- Deep understanding of machine learning algorithms
- Programming (Python, R)
- Research methodology
- Strong mathematical skills

  Essential tools:

- Python
- R
- TensorFlow
- PyTorch
- MATLAB

|&emsp;**Career**|&emsp;**Key Skills**|&emsp;**Essential Tools**|
| :- | :- | :- |
|&emsp;**Data Scientist**|&emsp;Statistical analysis, Programming (Python, R), Machine learning, Data visualization, Problem-solving|&emsp;Python, R, SQL, Hadoop, Spark, Tableau|
|&emsp;**Machine Learning Engineer**|&emsp;Programming (Python, Java, R), Machine learning algorithms, Statistics, System design|&emsp;Python, TensorFlow, Scikit-learn, PyTorch, Keras|
|&emsp;**Research Scientist**|&emsp;Deep understanding of machine learning algorithms, Programming (Python, R), Research methodology, Strong mathematical skills|&emsp;Python, R, TensorFlow, PyTorch, MATLAB|

  **How to Get Started in Machine Learning**

  Starting a journey in machine learning can seem daunting, but with the right approach and resources, anyone can learn this exciting field. Here are some steps to get you started:

  **Understand the basics**

  Before diving into machine learning, it's important to have a strong foundation in mathematics (especially statistics and linear algebra) and programming (Python is a popular choice due to its simplicity and the availability of machine learning libraries).

  There are many resources available to learn these basics. Online platforms like Khan Academy and Coursera offer courses in mathematics and programming. Books like "Think Stats" and "Python Crash Course" are also good starting points.

  **Choose the right tools**

  Choosing the right tools is crucial in machine learning. Python, along with libraries like NumPy, Pandas, and Scikit-learn, is a popular choice due to its simplicity and versatility.

  **Learn machine learning algorithms**

  Once you're comfortable with the basics, you can start learning about machine learning algorithms. Start with simple algorithms like linear regression and decision trees before moving on to more complex ones like neural networks.

  **Work on projects**

  Working on projects is a great way to gain practical experience and reinforce what you've learned. Start with simple projects like predicting house prices or classifying iris species, and gradually take on more complex projects. We have an article exploring **25 machine learning projects for all levels**, which can help you find something appropriate.


## Data science vs. machine learning

Data science is a field that studies data and how to extract meaning from it, whereas machine learning is a field devoted to understanding and building methods that utilize data to improve performance or inform predictions. Machine learning is a branch of artificial intelligence.

![image-7.png](attachment:image-7.png)

In recent years, machine learning and artificial intelligence (AI) have dominated parts of data science, playing a critical role in data analytics and business intelligence. Machine learning automates the process of data analysis and goes further to make predictions based on collecting and analyzing large amounts of data on certain populations. Models and algorithms are built to make this happen.

##### What is data science

Data science is a field that studies data and how to extract meaning from it, using a series of methods, algorithms, systems, and tools to extract insights from structured and unstructured data. This knowledge gets applied to business, government, and other industries to drive profits, innovate products and services, build better infrastructure and public systems, and more.

##### Skills needed

To build a career in data science, such as becoming a data scientist, you'll want to gain programming and data analytics skills.

- Strong knowledge of programming languages  R, SAS, and more
- Familiarity working with large amounts of structured and unstructured data
- Comfortable with processing and analyzing data for business needs
- Understanding of math, statistics, and probability
- Data visualization and data wrangling skills
- Knowledge of machine learning algorithms and models
- Good communication and teamwork skills

**Careers in data science**

Besides the obvious career as a data scientist, there are plenty of other data science jobs to choose from.

- Data scientist **:**  Uses data to understand and explain the phenomena around them, to help organizations make better decisions.

- Data analyst: Gathers, cleans, and studies data sets to help solve business problems.

- Data engineer: Build systems that collect, manage, and transform raw data into information for business analysts and data scientists.

- Data architect: Reviews and analyzes an organization's data infrastructure to plan databases and implement solutions to store and manage data.

- Business intelligence analyst: Gathers, cleans, and analyzes sales and customer data, interprets it, and shares findings with business teams.

##### What is machine learning?

Machine learning is a branch of artificial intelligence that uses algorithms to extract data and then predict future trends. Software is programmed with models that allow engineers to conduct statistical analysis to understand patterns in the data.

As an example, we all know that social media platforms like Facebook, Twitter, Instagram, YouTube, and TikTok gather users' information. Based on previous behavior, it it predicts interests and needs, and recommends products, services, or articles that are relevant to what you've searched before.

As a set of tools and concepts, machine learning is applied in data science, but also appears in fields beyond it. Data scientists often incorporate machine learning in their work where appropriate to help gather more information faster or to assist with trends analysis.

##### Skills needed

To become a successful machine learning engineer, you'll need to be well-versed in the following:

- Expertise in computer science, including data structures, algorithms, and architecture
- Strong understanding of statistics and probability
- Knowledge of software engineering and systems design
- Programming knowledge, such as Python, R, and more
- Ability to conduct data modeling and analysis

**Careers in machine learning**

If you decide to pursue a career in machine learning and artificial intelligence, there are several options to choose from.

- Machine learning engineer: Researches, builds, and designs the AI responsible for machine learning, and maintaining or improving AI systems

- AI engineer: Build AI development and production infrastructure, and then implements it

- Cloud engineer: Builds and maintains cloud infrastructure

- Computational linguist **:**  Develop and design computers that deal with how human language works


